三个模块
1.爬虫
	对每个网站定制（同类网站可能相同）
	采集数据后上传至数据库（通过pipeline（scrapy框架中的数据传输模块））
2.爬虫与主控间的通信
	写在pipeline里，好像scrapy本身有一部分API。
3.爬虫主控
	1.控制并log虫群的行为
	2.向上层提供（或通过数据库间接提供）现状log，
		与控制接口（起，停，部分起）。
		（但爬虫应该是尽可能实时运行的）。
4.初步的预处理
	做在哪里（过程中哪个阶段）还没计划，
	大概率做在主控过程里。
	对已爬取数据进行增量计划（爬完了再删还是放之前判断还是爬时判断）？
	以及其他可能的过程

可能的附加功能：
爬虫集群
	如果数据量太大，一个网站需由多个爬虫同步爬取，衍生出爬虫集群控制与数据去重问题）
	即同一个爬虫程序（代码）分进程运行多个。
	数据库集群（数据量太大，对数据库的I/O与储存）

环境需求：
语言：python3
要用到的python模块：scrapy, pymongo
要用到的软件：mongodb,(mySQL)
